{
 "metadata": {
  "name": "",
  "signature": "sha256:f2e6328c9da1f4e64dc6a28bcd7c0fd8a265f38a376f65861167d8a6ab0077ba"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Predicting Breast Cancer"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You've just been hired by the Chief Oncologist of Seattle Grace Hospital.   She wants to develop a less invasive test for idenfying malignant tumors in breast tissue.  She's teamed up with a west coast technology company to develop a system that can scan tumors without biopsy.  She's hired you to determine if it's possible to use these scans to determine if a tumor is malignant or benign.   \n",
      "\n",
      "Your job is to determine if it's possible to create a machine learning model that can predict if a tumor is malignant or benign using the given data. \n",
      "\n",
      "Rules\n",
      "\n",
      "* You should use a random forest\n",
      "* You may use any or all of the features.\n",
      "\n",
      "Deliverables\n",
      "\n",
      "1.  You will need to produce a document that explains:\n",
      "\n",
      "A)  Were you successful in attempting to create a machine learning model to predict malignant tumors.\n",
      "\n",
      "B) The hospitals lawyers are VERY careful and are worred about the accuracy of your model.  You'll need to inform them of the risks of using your system, and possibly convince them of it's safety.  \n",
      "\n",
      "1.  How good is your model?  \n",
      "\n",
      "2.  How likely is it fasely predict breast cancer?\n",
      "\n",
      "3.  How likely is it to miss a malignant case?\n",
      "\n",
      "C)  The Chief Oncologist needs to be convinced that the system is making 'realistic' choices and wants to understand which variables are the most important in predicting cancer.   Explain or show the Doctor which variables are most important.\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Most important parameters (and what they mean)\n",
      " * ###Parameters that will make your model better\n",
      "  * <b>n_estimators</b>: The number of trees in the forest. Choose as high of a number as your computer can handle.\n",
      "  * <b>max_features</b>: The number of features to consider when looking for the best split. Try [\"auto\", \"None\", \"sqrt\", \"log2\", 0.9, and 0.2]\n",
      "  * <b>min_samples_leaf</b>: The minimum number of samples in newly created leaves.Try [1, 2, 3]. If 3 is the best, try higher numbers.\n",
      " * ###Parameters that will make it easier to train your model\n",
      "  * <b>n_jobs</b>: Determines if multiple processors should be used to train and test the model. Always set this to -1 and %%timeit vs. if it is set to 1. It should be much faster (especially when many trees are trained).\n",
      "  * <b>random_state</b>: Set this to 42 if you want to be cool AND want others to be able to replicate your results.\n",
      " "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.metrics import roc_auc_score\n",
      "from sklearn.metrics import classification_report\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "X = pd.read_csv(\"breast_cancer.csv\")\n",
      "y = X.pop(\"malignant\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Unnamed: 0</th>\n",
        "      <th>id number</th>\n",
        "      <th>clump_thickness</th>\n",
        "      <th>uniformity_of_cell_size</th>\n",
        "      <th>uniformity_of_cell_shape</th>\n",
        "      <th>marginal_adhesion</th>\n",
        "      <th>epithelial_cell_size</th>\n",
        "      <th>bare_nuclei</th>\n",
        "      <th>bland_chromatin</th>\n",
        "      <th>normal_nucleoli</th>\n",
        "      <th>mitoses</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td> 699.000000</td>\n",
        "      <td>      699.000000</td>\n",
        "      <td> 699.000000</td>\n",
        "      <td> 699.000000</td>\n",
        "      <td> 699.000000</td>\n",
        "      <td> 699.000000</td>\n",
        "      <td> 699.000000</td>\n",
        "      <td> 699.000000</td>\n",
        "      <td> 699.000000</td>\n",
        "      <td> 699.000000</td>\n",
        "      <td> 699.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mean</th>\n",
        "      <td> 349.000000</td>\n",
        "      <td>  1071704.098712</td>\n",
        "      <td>   4.417740</td>\n",
        "      <td>   3.134478</td>\n",
        "      <td>   3.207439</td>\n",
        "      <td>   2.806867</td>\n",
        "      <td>   3.216023</td>\n",
        "      <td>   3.440629</td>\n",
        "      <td>   3.437768</td>\n",
        "      <td>   2.866953</td>\n",
        "      <td>   1.589413</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>std</th>\n",
        "      <td> 201.928205</td>\n",
        "      <td>   617095.729819</td>\n",
        "      <td>   2.815741</td>\n",
        "      <td>   3.051459</td>\n",
        "      <td>   2.971913</td>\n",
        "      <td>   2.855379</td>\n",
        "      <td>   2.214300</td>\n",
        "      <td>   3.665507</td>\n",
        "      <td>   2.438364</td>\n",
        "      <td>   3.053634</td>\n",
        "      <td>   1.715078</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>min</th>\n",
        "      <td>   0.000000</td>\n",
        "      <td>    61634.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>  -1.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25%</th>\n",
        "      <td> 174.500000</td>\n",
        "      <td>   870688.500000</td>\n",
        "      <td>   2.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   2.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   2.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50%</th>\n",
        "      <td> 349.000000</td>\n",
        "      <td>  1171710.000000</td>\n",
        "      <td>   4.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   2.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   3.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75%</th>\n",
        "      <td> 523.500000</td>\n",
        "      <td>  1238298.000000</td>\n",
        "      <td>   6.000000</td>\n",
        "      <td>   5.000000</td>\n",
        "      <td>   5.000000</td>\n",
        "      <td>   4.000000</td>\n",
        "      <td>   4.000000</td>\n",
        "      <td>   5.000000</td>\n",
        "      <td>   5.000000</td>\n",
        "      <td>   4.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>max</th>\n",
        "      <td> 698.000000</td>\n",
        "      <td> 13454352.000000</td>\n",
        "      <td>  10.000000</td>\n",
        "      <td>  10.000000</td>\n",
        "      <td>  10.000000</td>\n",
        "      <td>  10.000000</td>\n",
        "      <td>  10.000000</td>\n",
        "      <td>  10.000000</td>\n",
        "      <td>  10.000000</td>\n",
        "      <td>  10.000000</td>\n",
        "      <td>  10.000000</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "       Unnamed: 0        id number  clump_thickness  uniformity_of_cell_size  \\\n",
        "count  699.000000       699.000000       699.000000               699.000000   \n",
        "mean   349.000000   1071704.098712         4.417740                 3.134478   \n",
        "std    201.928205    617095.729819         2.815741                 3.051459   \n",
        "min      0.000000     61634.000000         1.000000                 1.000000   \n",
        "25%    174.500000    870688.500000         2.000000                 1.000000   \n",
        "50%    349.000000   1171710.000000         4.000000                 1.000000   \n",
        "75%    523.500000   1238298.000000         6.000000                 5.000000   \n",
        "max    698.000000  13454352.000000        10.000000                10.000000   \n",
        "\n",
        "       uniformity_of_cell_shape  marginal_adhesion  epithelial_cell_size  \\\n",
        "count                699.000000         699.000000            699.000000   \n",
        "mean                   3.207439           2.806867              3.216023   \n",
        "std                    2.971913           2.855379              2.214300   \n",
        "min                    1.000000           1.000000              1.000000   \n",
        "25%                    1.000000           1.000000              2.000000   \n",
        "50%                    1.000000           1.000000              2.000000   \n",
        "75%                    5.000000           4.000000              4.000000   \n",
        "max                   10.000000          10.000000             10.000000   \n",
        "\n",
        "       bare_nuclei  bland_chromatin  normal_nucleoli     mitoses  \n",
        "count   699.000000       699.000000       699.000000  699.000000  \n",
        "mean      3.440629         3.437768         2.866953    1.589413  \n",
        "std       3.665507         2.438364         3.053634    1.715078  \n",
        "min      -1.000000         1.000000         1.000000    1.000000  \n",
        "25%       1.000000         2.000000         1.000000    1.000000  \n",
        "50%       1.000000         3.000000         1.000000    1.000000  \n",
        "75%       5.000000         5.000000         4.000000    1.000000  \n",
        "max      10.000000        10.000000        10.000000   10.000000  "
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Appears all categories except id number are categorical"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get just the numeric variables by selecting only the variables that are not \"object\" datatypes.\n",
      "numeric_variables = list(X.dtypes[X.dtypes != \"object\"].index)\n",
      "X[numeric_variables].head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Unnamed: 0</th>\n",
        "      <th>id number</th>\n",
        "      <th>clump_thickness</th>\n",
        "      <th>uniformity_of_cell_size</th>\n",
        "      <th>uniformity_of_cell_shape</th>\n",
        "      <th>marginal_adhesion</th>\n",
        "      <th>epithelial_cell_size</th>\n",
        "      <th>bare_nuclei</th>\n",
        "      <th>bland_chromatin</th>\n",
        "      <th>normal_nucleoli</th>\n",
        "      <th>mitoses</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1000025</td>\n",
        "      <td> 5</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 2</td>\n",
        "      <td>  1</td>\n",
        "      <td> 3</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 1</td>\n",
        "      <td> 1002945</td>\n",
        "      <td> 5</td>\n",
        "      <td> 4</td>\n",
        "      <td> 4</td>\n",
        "      <td> 5</td>\n",
        "      <td> 7</td>\n",
        "      <td> 10</td>\n",
        "      <td> 3</td>\n",
        "      <td> 2</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 2</td>\n",
        "      <td> 1015425</td>\n",
        "      <td> 3</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 2</td>\n",
        "      <td>  2</td>\n",
        "      <td> 3</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 3</td>\n",
        "      <td> 1016277</td>\n",
        "      <td> 6</td>\n",
        "      <td> 8</td>\n",
        "      <td> 8</td>\n",
        "      <td> 1</td>\n",
        "      <td> 3</td>\n",
        "      <td>  4</td>\n",
        "      <td> 3</td>\n",
        "      <td> 7</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 4</td>\n",
        "      <td> 1017023</td>\n",
        "      <td> 4</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 3</td>\n",
        "      <td> 2</td>\n",
        "      <td>  1</td>\n",
        "      <td> 3</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 38,
       "text": [
        "   Unnamed: 0  id number  clump_thickness  uniformity_of_cell_size  \\\n",
        "0           0    1000025                5                        1   \n",
        "1           1    1002945                5                        4   \n",
        "2           2    1015425                3                        1   \n",
        "3           3    1016277                6                        8   \n",
        "4           4    1017023                4                        1   \n",
        "\n",
        "   uniformity_of_cell_shape  marginal_adhesion  epithelial_cell_size  \\\n",
        "0                         1                  1                     2   \n",
        "1                         4                  5                     7   \n",
        "2                         1                  1                     2   \n",
        "3                         8                  1                     3   \n",
        "4                         1                  3                     2   \n",
        "\n",
        "   bare_nuclei  bland_chromatin  normal_nucleoli  mitoses  \n",
        "0            1                3                1        1  \n",
        "1           10                3                2        1  \n",
        "2            2                3                1        1  \n",
        "3            4                3                7        1  \n",
        "4            1                3                1        1  "
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "id Number looks like a worthless variable. \n",
      "I am interested in seeing if it is useful for prediction. It might be useful if the id was assigned in some non-random way. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
      "\n",
      "# only use numeric_variables because I have yet to dummy out the categorical variables\n",
      "model.fit(X[numeric_variables], y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 39,
       "text": [
        "RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=None, max_features='auto',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, n_estimators=100, n_jobs=1,\n",
        "            oob_score=False, random_state=42, verbose=0)"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Drop the variables I don't feel like dealing with for this tutorial\n",
      "X.drop([\"Unnamed: 0\", \"id number\"], axis=1, inplace=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>clump_thickness</th>\n",
        "      <th>uniformity_of_cell_size</th>\n",
        "      <th>uniformity_of_cell_shape</th>\n",
        "      <th>marginal_adhesion</th>\n",
        "      <th>epithelial_cell_size</th>\n",
        "      <th>bare_nuclei</th>\n",
        "      <th>bland_chromatin</th>\n",
        "      <th>normal_nucleoli</th>\n",
        "      <th>mitoses</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0  </th>\n",
        "      <td>  5</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  3</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1  </th>\n",
        "      <td>  5</td>\n",
        "      <td>  4</td>\n",
        "      <td>  4</td>\n",
        "      <td>  5</td>\n",
        "      <td> 7</td>\n",
        "      <td> 10</td>\n",
        "      <td>  3</td>\n",
        "      <td>  2</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2  </th>\n",
        "      <td>  3</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 2</td>\n",
        "      <td>  2</td>\n",
        "      <td>  3</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3  </th>\n",
        "      <td>  6</td>\n",
        "      <td>  8</td>\n",
        "      <td>  8</td>\n",
        "      <td>  1</td>\n",
        "      <td> 3</td>\n",
        "      <td>  4</td>\n",
        "      <td>  3</td>\n",
        "      <td>  7</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4  </th>\n",
        "      <td>  4</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  3</td>\n",
        "      <td> 2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  3</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5  </th>\n",
        "      <td>  8</td>\n",
        "      <td> 10</td>\n",
        "      <td> 10</td>\n",
        "      <td>  8</td>\n",
        "      <td> 7</td>\n",
        "      <td> 10</td>\n",
        "      <td>  9</td>\n",
        "      <td>  7</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6  </th>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 2</td>\n",
        "      <td> 10</td>\n",
        "      <td>  3</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7  </th>\n",
        "      <td>  2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  2</td>\n",
        "      <td>  1</td>\n",
        "      <td> 2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  3</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8  </th>\n",
        "      <td>  2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 5</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9  </th>\n",
        "      <td>  4</td>\n",
        "      <td>  2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  2</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10 </th>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  3</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11 </th>\n",
        "      <td>  2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  2</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12 </th>\n",
        "      <td>  5</td>\n",
        "      <td>  3</td>\n",
        "      <td>  3</td>\n",
        "      <td>  3</td>\n",
        "      <td> 2</td>\n",
        "      <td>  3</td>\n",
        "      <td>  4</td>\n",
        "      <td>  4</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13 </th>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 2</td>\n",
        "      <td>  3</td>\n",
        "      <td>  3</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14 </th>\n",
        "      <td>  8</td>\n",
        "      <td>  7</td>\n",
        "      <td>  5</td>\n",
        "      <td> 10</td>\n",
        "      <td> 7</td>\n",
        "      <td>  9</td>\n",
        "      <td>  5</td>\n",
        "      <td>  5</td>\n",
        "      <td> 4</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>15 </th>\n",
        "      <td>  7</td>\n",
        "      <td>  4</td>\n",
        "      <td>  6</td>\n",
        "      <td>  4</td>\n",
        "      <td> 6</td>\n",
        "      <td>  1</td>\n",
        "      <td>  4</td>\n",
        "      <td>  3</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16 </th>\n",
        "      <td>  4</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  2</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17 </th>\n",
        "      <td>  4</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  3</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>18 </th>\n",
        "      <td> 10</td>\n",
        "      <td>  7</td>\n",
        "      <td>  7</td>\n",
        "      <td>  6</td>\n",
        "      <td> 4</td>\n",
        "      <td> 10</td>\n",
        "      <td>  4</td>\n",
        "      <td>  1</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19 </th>\n",
        "      <td>  6</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  3</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>20 </th>\n",
        "      <td>  7</td>\n",
        "      <td>  3</td>\n",
        "      <td>  2</td>\n",
        "      <td> 10</td>\n",
        "      <td> 5</td>\n",
        "      <td> 10</td>\n",
        "      <td>  5</td>\n",
        "      <td>  4</td>\n",
        "      <td> 4</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>21 </th>\n",
        "      <td> 10</td>\n",
        "      <td>  5</td>\n",
        "      <td>  5</td>\n",
        "      <td>  3</td>\n",
        "      <td> 6</td>\n",
        "      <td>  7</td>\n",
        "      <td>  7</td>\n",
        "      <td> 10</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>22 </th>\n",
        "      <td>  3</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  2</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>23 </th>\n",
        "      <td>  8</td>\n",
        "      <td>  4</td>\n",
        "      <td>  5</td>\n",
        "      <td>  1</td>\n",
        "      <td> 2</td>\n",
        "      <td> -1</td>\n",
        "      <td>  7</td>\n",
        "      <td>  3</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>24 </th>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  3</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25 </th>\n",
        "      <td>  5</td>\n",
        "      <td>  2</td>\n",
        "      <td>  3</td>\n",
        "      <td>  4</td>\n",
        "      <td> 2</td>\n",
        "      <td>  7</td>\n",
        "      <td>  3</td>\n",
        "      <td>  6</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>26 </th>\n",
        "      <td>  3</td>\n",
        "      <td>  2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  2</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>27 </th>\n",
        "      <td>  5</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  2</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>28 </th>\n",
        "      <td>  2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  2</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>29 </th>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  3</td>\n",
        "      <td>  1</td>\n",
        "      <td> 2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>...</th>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>669</th>\n",
        "      <td>  5</td>\n",
        "      <td> 10</td>\n",
        "      <td> 10</td>\n",
        "      <td>  8</td>\n",
        "      <td> 5</td>\n",
        "      <td>  5</td>\n",
        "      <td>  7</td>\n",
        "      <td> 10</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>670</th>\n",
        "      <td>  3</td>\n",
        "      <td> 10</td>\n",
        "      <td>  7</td>\n",
        "      <td>  8</td>\n",
        "      <td> 5</td>\n",
        "      <td>  8</td>\n",
        "      <td>  7</td>\n",
        "      <td>  4</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>671</th>\n",
        "      <td>  3</td>\n",
        "      <td>  2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  2</td>\n",
        "      <td> 2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  3</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>672</th>\n",
        "      <td>  2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  3</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>673</th>\n",
        "      <td>  5</td>\n",
        "      <td>  3</td>\n",
        "      <td>  2</td>\n",
        "      <td>  1</td>\n",
        "      <td> 3</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>674</th>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  2</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>675</th>\n",
        "      <td>  4</td>\n",
        "      <td>  1</td>\n",
        "      <td>  4</td>\n",
        "      <td>  1</td>\n",
        "      <td> 2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>676</th>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  2</td>\n",
        "      <td>  1</td>\n",
        "      <td> 2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  2</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>677</th>\n",
        "      <td>  5</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>678</th>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>679</th>\n",
        "      <td>  2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>680</th>\n",
        "      <td> 10</td>\n",
        "      <td> 10</td>\n",
        "      <td> 10</td>\n",
        "      <td> 10</td>\n",
        "      <td> 5</td>\n",
        "      <td> 10</td>\n",
        "      <td> 10</td>\n",
        "      <td> 10</td>\n",
        "      <td> 7</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>681</th>\n",
        "      <td>  5</td>\n",
        "      <td> 10</td>\n",
        "      <td> 10</td>\n",
        "      <td> 10</td>\n",
        "      <td> 4</td>\n",
        "      <td> 10</td>\n",
        "      <td>  5</td>\n",
        "      <td>  6</td>\n",
        "      <td> 3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>682</th>\n",
        "      <td>  5</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  3</td>\n",
        "      <td>  2</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>683</th>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>684</th>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>685</th>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>686</th>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>687</th>\n",
        "      <td>  3</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  2</td>\n",
        "      <td>  3</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>688</th>\n",
        "      <td>  4</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>689</th>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 8</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>690</th>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  3</td>\n",
        "      <td> 2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>691</th>\n",
        "      <td>  5</td>\n",
        "      <td> 10</td>\n",
        "      <td> 10</td>\n",
        "      <td>  5</td>\n",
        "      <td> 4</td>\n",
        "      <td>  5</td>\n",
        "      <td>  4</td>\n",
        "      <td>  4</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>692</th>\n",
        "      <td>  3</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>693</th>\n",
        "      <td>  3</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  2</td>\n",
        "      <td>  1</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>694</th>\n",
        "      <td>  3</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 3</td>\n",
        "      <td>  2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>695</th>\n",
        "      <td>  2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>696</th>\n",
        "      <td>  5</td>\n",
        "      <td> 10</td>\n",
        "      <td> 10</td>\n",
        "      <td>  3</td>\n",
        "      <td> 7</td>\n",
        "      <td>  3</td>\n",
        "      <td>  8</td>\n",
        "      <td> 10</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>697</th>\n",
        "      <td>  4</td>\n",
        "      <td>  8</td>\n",
        "      <td>  6</td>\n",
        "      <td>  4</td>\n",
        "      <td> 3</td>\n",
        "      <td>  4</td>\n",
        "      <td> 10</td>\n",
        "      <td>  6</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>698</th>\n",
        "      <td>  4</td>\n",
        "      <td>  8</td>\n",
        "      <td>  8</td>\n",
        "      <td>  5</td>\n",
        "      <td> 4</td>\n",
        "      <td>  5</td>\n",
        "      <td> 10</td>\n",
        "      <td>  4</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>699 rows \u00d7 9 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "     clump_thickness  uniformity_of_cell_size  uniformity_of_cell_shape  \\\n",
        "0                  5                        1                         1   \n",
        "1                  5                        4                         4   \n",
        "2                  3                        1                         1   \n",
        "3                  6                        8                         8   \n",
        "4                  4                        1                         1   \n",
        "5                  8                       10                        10   \n",
        "6                  1                        1                         1   \n",
        "7                  2                        1                         2   \n",
        "8                  2                        1                         1   \n",
        "9                  4                        2                         1   \n",
        "10                 1                        1                         1   \n",
        "11                 2                        1                         1   \n",
        "12                 5                        3                         3   \n",
        "13                 1                        1                         1   \n",
        "14                 8                        7                         5   \n",
        "15                 7                        4                         6   \n",
        "16                 4                        1                         1   \n",
        "17                 4                        1                         1   \n",
        "18                10                        7                         7   \n",
        "19                 6                        1                         1   \n",
        "20                 7                        3                         2   \n",
        "21                10                        5                         5   \n",
        "22                 3                        1                         1   \n",
        "23                 8                        4                         5   \n",
        "24                 1                        1                         1   \n",
        "25                 5                        2                         3   \n",
        "26                 3                        2                         1   \n",
        "27                 5                        1                         1   \n",
        "28                 2                        1                         1   \n",
        "29                 1                        1                         3   \n",
        "..               ...                      ...                       ...   \n",
        "669                5                       10                        10   \n",
        "670                3                       10                         7   \n",
        "671                3                        2                         1   \n",
        "672                2                        1                         1   \n",
        "673                5                        3                         2   \n",
        "674                1                        1                         1   \n",
        "675                4                        1                         4   \n",
        "676                1                        1                         2   \n",
        "677                5                        1                         1   \n",
        "678                1                        1                         1   \n",
        "679                2                        1                         1   \n",
        "680               10                       10                        10   \n",
        "681                5                       10                        10   \n",
        "682                5                        1                         1   \n",
        "683                1                        1                         1   \n",
        "684                1                        1                         1   \n",
        "685                1                        1                         1   \n",
        "686                1                        1                         1   \n",
        "687                3                        1                         1   \n",
        "688                4                        1                         1   \n",
        "689                1                        1                         1   \n",
        "690                1                        1                         1   \n",
        "691                5                       10                        10   \n",
        "692                3                        1                         1   \n",
        "693                3                        1                         1   \n",
        "694                3                        1                         1   \n",
        "695                2                        1                         1   \n",
        "696                5                       10                        10   \n",
        "697                4                        8                         6   \n",
        "698                4                        8                         8   \n",
        "\n",
        "     marginal_adhesion  epithelial_cell_size  bare_nuclei  bland_chromatin  \\\n",
        "0                    1                     2            1                3   \n",
        "1                    5                     7           10                3   \n",
        "2                    1                     2            2                3   \n",
        "3                    1                     3            4                3   \n",
        "4                    3                     2            1                3   \n",
        "5                    8                     7           10                9   \n",
        "6                    1                     2           10                3   \n",
        "7                    1                     2            1                3   \n",
        "8                    1                     2            1                1   \n",
        "9                    1                     2            1                2   \n",
        "10                   1                     1            1                3   \n",
        "11                   1                     2            1                2   \n",
        "12                   3                     2            3                4   \n",
        "13                   1                     2            3                3   \n",
        "14                  10                     7            9                5   \n",
        "15                   4                     6            1                4   \n",
        "16                   1                     2            1                2   \n",
        "17                   1                     2            1                3   \n",
        "18                   6                     4           10                4   \n",
        "19                   1                     2            1                3   \n",
        "20                  10                     5           10                5   \n",
        "21                   3                     6            7                7   \n",
        "22                   1                     2            1                2   \n",
        "23                   1                     2           -1                7   \n",
        "24                   1                     2            1                3   \n",
        "25                   4                     2            7                3   \n",
        "26                   1                     1            1                2   \n",
        "27                   1                     2            1                2   \n",
        "28                   1                     2            1                2   \n",
        "29                   1                     2            1                1   \n",
        "..                 ...                   ...          ...              ...   \n",
        "669                  8                     5            5                7   \n",
        "670                  8                     5            8                7   \n",
        "671                  2                     2            1                3   \n",
        "672                  1                     2            1                3   \n",
        "673                  1                     3            1                1   \n",
        "674                  1                     2            1                2   \n",
        "675                  1                     2            1                1   \n",
        "676                  1                     2            1                2   \n",
        "677                  1                     2            1                1   \n",
        "678                  1                     2            1                1   \n",
        "679                  1                     2            1                1   \n",
        "680                 10                     5           10               10   \n",
        "681                 10                     4           10                5   \n",
        "682                  1                     2            1                3   \n",
        "683                  1                     2            1                1   \n",
        "684                  1                     2            1                1   \n",
        "685                  1                     2            1                1   \n",
        "686                  1                     2            1                1   \n",
        "687                  1                     2            1                2   \n",
        "688                  1                     2            1                1   \n",
        "689                  1                     2            1                1   \n",
        "690                  3                     2            1                1   \n",
        "691                  5                     4            5                4   \n",
        "692                  1                     2            1                1   \n",
        "693                  1                     2            1                2   \n",
        "694                  1                     3            2                1   \n",
        "695                  1                     2            1                1   \n",
        "696                  3                     7            3                8   \n",
        "697                  4                     3            4               10   \n",
        "698                  5                     4            5               10   \n",
        "\n",
        "     normal_nucleoli  mitoses  \n",
        "0                  1        1  \n",
        "1                  2        1  \n",
        "2                  1        1  \n",
        "3                  7        1  \n",
        "4                  1        1  \n",
        "5                  7        1  \n",
        "6                  1        1  \n",
        "7                  1        1  \n",
        "8                  1        5  \n",
        "9                  1        1  \n",
        "10                 1        1  \n",
        "11                 1        1  \n",
        "12                 4        1  \n",
        "13                 1        1  \n",
        "14                 5        4  \n",
        "15                 3        1  \n",
        "16                 1        1  \n",
        "17                 1        1  \n",
        "18                 1        2  \n",
        "19                 1        1  \n",
        "20                 4        4  \n",
        "21                10        1  \n",
        "22                 1        1  \n",
        "23                 3        1  \n",
        "24                 1        1  \n",
        "25                 6        1  \n",
        "26                 1        1  \n",
        "27                 1        1  \n",
        "28                 1        1  \n",
        "29                 1        1  \n",
        "..               ...      ...  \n",
        "669               10        1  \n",
        "670                4        1  \n",
        "671                1        1  \n",
        "672                1        1  \n",
        "673                1        1  \n",
        "674                1        1  \n",
        "675                1        1  \n",
        "676                1        1  \n",
        "677                1        1  \n",
        "678                1        1  \n",
        "679                1        1  \n",
        "680               10        7  \n",
        "681                6        3  \n",
        "682                2        1  \n",
        "683                1        1  \n",
        "684                1        1  \n",
        "685                1        1  \n",
        "686                1        1  \n",
        "687                3        1  \n",
        "688                1        1  \n",
        "689                1        8  \n",
        "690                1        1  \n",
        "691                4        1  \n",
        "692                1        1  \n",
        "693                1        2  \n",
        "694                1        1  \n",
        "695                1        1  \n",
        "696               10        2  \n",
        "697                6        1  \n",
        "698                4        1  \n",
        "\n",
        "[699 rows x 9 columns]"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Look at all the columns in the dataset\n",
      "def printall(X, max_rows=10):\n",
      "    from IPython.display import display, HTML\n",
      "    display(HTML(X.to_html(max_rows=max_rows)))\n",
      "    \n",
      "printall(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>clump_thickness</th>\n",
        "      <th>uniformity_of_cell_size</th>\n",
        "      <th>uniformity_of_cell_shape</th>\n",
        "      <th>marginal_adhesion</th>\n",
        "      <th>epithelial_cell_size</th>\n",
        "      <th>bare_nuclei</th>\n",
        "      <th>bland_chromatin</th>\n",
        "      <th>normal_nucleoli</th>\n",
        "      <th>mitoses</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0  </th>\n",
        "      <td> 5</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  3</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1  </th>\n",
        "      <td> 5</td>\n",
        "      <td>  4</td>\n",
        "      <td>  4</td>\n",
        "      <td> 5</td>\n",
        "      <td> 7</td>\n",
        "      <td> 10</td>\n",
        "      <td>  3</td>\n",
        "      <td>  2</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2  </th>\n",
        "      <td> 3</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 2</td>\n",
        "      <td>  2</td>\n",
        "      <td>  3</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3  </th>\n",
        "      <td> 6</td>\n",
        "      <td>  8</td>\n",
        "      <td>  8</td>\n",
        "      <td> 1</td>\n",
        "      <td> 3</td>\n",
        "      <td>  4</td>\n",
        "      <td>  3</td>\n",
        "      <td>  7</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4  </th>\n",
        "      <td> 4</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 3</td>\n",
        "      <td> 2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  3</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>...</th>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>694</th>\n",
        "      <td> 3</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 3</td>\n",
        "      <td>  2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>695</th>\n",
        "      <td> 2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 2</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>696</th>\n",
        "      <td> 5</td>\n",
        "      <td> 10</td>\n",
        "      <td> 10</td>\n",
        "      <td> 3</td>\n",
        "      <td> 7</td>\n",
        "      <td>  3</td>\n",
        "      <td>  8</td>\n",
        "      <td> 10</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>697</th>\n",
        "      <td> 4</td>\n",
        "      <td>  8</td>\n",
        "      <td>  6</td>\n",
        "      <td> 4</td>\n",
        "      <td> 3</td>\n",
        "      <td>  4</td>\n",
        "      <td> 10</td>\n",
        "      <td>  6</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>698</th>\n",
        "      <td> 4</td>\n",
        "      <td>  8</td>\n",
        "      <td>  8</td>\n",
        "      <td> 5</td>\n",
        "      <td> 4</td>\n",
        "      <td>  5</td>\n",
        "      <td> 10</td>\n",
        "      <td>  4</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x1094ead90>"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#remember to scale our features, as with linear regression\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "scaler = StandardScaler()\n",
      "X= scaler.fit_transform(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.metrics import accuracy_score\n",
      "model = LogisticRegression(penalty='l2', C=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 46,
       "text": [
        "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Logistic accuracy is %2.2f\" % accuracy_score(y_test,model.predict(X_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Logistic accuracy is 0.97\n"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = RandomForestClassifier(100, n_jobs=-1, random_state=42)\n",
      "model.fit(X, y)\n",
      "print \"C-stat: \", roc_auc_score(y_test, model.predict_proba(X_test)[:,1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C-stat:  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.0\n"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Variable importance measures"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Parameter tests"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Parameters to test\n",
      "\n",
      " * ###Parameters that will make your model better\n",
      "  * <b>n_estimators</b>: The number of trees in the forest. Choose as high of a number as your computer can handle.\n",
      "  * <b>max_features</b>: The number of features to consider when looking for the best split. Try [\"auto\", \"None\", \"sqrt\", \"log2\", 0.9, and 0.2]\n",
      "  * <b>min_samples_leaf</b>: The minimum number of samples in newly created leaves.Try [1, 2, 3]. If 3 is the best, try higher numbers such as 1 through 10.\n",
      " * ###Parameters that will make it easier to train your model\n",
      "  * <b>n_jobs</b>: Determines if multiple processors should be used to train and test the model. Always set this to -1 and %%timeit vs. if it is set to 1. It should be much faster (especially when many trees are trained)."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "n_jobs"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%timeit\n",
      "model = RandomForestClassifier(1000, n_jobs=1, random_state=42)\n",
      "model.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 716 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%timeit\n",
      "model = RandomForestClassifier(1000, n_jobs=-1, random_state=42)\n",
      "model.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 842 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "n_estimators"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results = []\n",
      "n_estimator_options = [30, 50, 100, 200, 500, 1000, 2000]\n",
      "\n",
      "for trees in n_estimator_options:\n",
      "    model = RandomForestClassifier(trees, n_jobs=-1, random_state=42)\n",
      "    model.fit(X, y)\n",
      "    print trees, \"trees\"\n",
      "    roc = roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
      "    print \"C-stat: \", roc\n",
      "    results.append(roc)\n",
      "    print \"\"\n",
      "    \n",
      "pd.Series(results, n_estimator_options).plot();"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "30 trees\n",
        "C-stat: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.0\n",
        "\n",
        "50"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " trees\n",
        "C-stat: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.0\n",
        "\n",
        "100"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " trees\n",
        "C-stat: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.0\n",
        "\n",
        "200"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " trees\n",
        "C-stat: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.0\n",
        "\n",
        "500"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " trees\n",
        "C-stat: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.0\n",
        "\n",
        "1000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " trees\n",
        "C-stat: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.0\n",
        "\n",
        "2000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " trees\n",
        "C-stat: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.0\n",
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEACAYAAAC+gnFaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNOUsBJI05SwEkjTl/heJ28z+OKKHKwAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10a833a10>"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "max_features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results = []\n",
      "max_features_options = [\"auto\", None, \"sqrt\", \"log2\", 0.9, 0.2]\n",
      "\n",
      "for max_features in max_features_options:\n",
      "    model = RandomForestClassifier(n_estimators=1000, n_jobs=-1, random_state=42, max_features=max_features)\n",
      "    model.fit(X, y)\n",
      "    print max_features, \"option\"\n",
      "    roc =  roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
      "    print \"C-stat: \", roc\n",
      "    results.append(roc)\n",
      "    print \"\"\n",
      "    \n",
      "pd.Series(results, max_features_options).plot(kind=\"barh\", xlim=(.991,.995));"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "auto option\n",
        "C-stat: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.0\n",
        "\n",
        "None"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " option\n",
        "C-stat: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.0\n",
        "\n",
        "sqrt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " option\n",
        "C-stat: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.0\n",
        "\n",
        "log2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " option\n",
        "C-stat: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.0\n",
        "\n",
        "0.9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " option\n",
        "C-stat: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.0\n",
        "\n",
        "0.2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " option\n",
        "C-stat: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.0\n",
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD7CAYAAAB0d9PAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFudJREFUeJzt3X+0ZWdd3/H3l5AsMZBMkEBpEpgQKQQ0JKadQontYCQE\nESPBtrLAxRClWV0FoghFdLUTjaWhEVFbYYliMIWIIMEF1ICo8wArjQEhMxlkJuQHUwi0pXWBhgoS\nkm//uPuWw+295+5zZu/7PPvm/VrrrLt/nL335z4D95vzfO++OzITSZI28oDaASRJbbNQSJLmslBI\nkuayUEiS5rJQSJLmslBIkuZ6YO0Aa0WEv68rSQvKzBjr3E1+osjM5l979+6tnmE7ZDSnOVt/TSHn\n2JosFFNw5MiR2hE2NYWMYM6hmXNYU8k5JguFJGkuC8WS9uzZUzvCpqaQEcw5NHMOayo5xxRbMb+1\niIjI1jJJUssigry/NbOnoJRSO8KmppARzDk0cw5rKjnHZKGQJM3l1JMkTdzYU0/N3XAHK9+0JKkN\njU495QRe+xrIsB0ymtOcrb+mkHNcjRYKSVIrmuxRbEWFlKTtw1+PlSRVNFihiIgLI+JwRNwWEa9a\nZ//zI+JARNwSETdExFlDXbuOUjtAD6V2gJ5K7QA9ldoBeiq1A/RUagfoqdQOUN0ghSIijgH+E3Ah\n8ATgeRFx5pq33Qn848w8C7gCeNMQ15YkjWuQHkVEPAXYm5kXdus/A5CZV27w/pOAg5l56jr77FFI\n0kKm0aM4BfjczPpd3baN/DjwhwNdW5I0oqFuuOv9ESAingZcAjx143ftAXZ2yzuAs4Hd3XrpvtZe\nX93WSp711tdmrZ1no/X9wE82lGej9dXlVvJstO54bv/xXF0+wlYYaurpycDlM1NPrwbuy8zXrnnf\nWcB1wIWZefsG55rI1FPhm/94rSq0nxHMObSCOYdUaD/nuFNPQxWKBwK3AucDXwA+CjwvMw/NvOdR\nwJ8CL8jMP5tzrokUCklqxQT+1lNmfiMiXgJ8ADgGeHNmHoqIS7v9vwH8W+Ak4I3d33K6JzN3DXF9\nSdJ4vDN7aYX2P44W2s8I5hxawZxDKrSfcxq/9SRJ2qb8RCFJk+cnCklSRRaKpZXaAXootQP0VGoH\n6KnUDtBTqR2gp1I7QE+ldoDqLBSSpLmafBQq+ChUSWpFk4WitQa7JLWsuzdtNE49LamUUjvCpqaQ\nEcw5NHMOayo5x2ShkCTN1eR9FK1lkqSWRXgfhSSpIgvFkqYwbzmFjGDOoZlzWFPJOSYLhSRpLnsU\nkjRx9igkSVVZKJY0hXnLKWQEcw7NnMOaSs4xWSgkSXPZo5CkibNHIUmqykKxpCnMW04hI5hzaOYc\n1lRyjslCIUmayx6FJE2cPQpJUlVNPrho7IdwSJL6a/QTRU7gta+BDNshoznN2fprCjnH1WSPYiu+\ncUnaPuxRSJIqslAsrdQO0EOpHaCnUjtAT6V2gJ5K7QA9ldoBeiq1A1Q3WKGIiAsj4nBE3BYRr1pn\n/0kR8e6IOBARN0XEE4e6tiRpPIP0KCLiGOBW4PuBzwMfA56XmYdm3nMV8NeZeUVEPA749cz8/nXO\nZY9CkhYyjR7FLuD2zDySmfcAbwcuWvOeM1n59QEy81ZgZ0ScPND1JUkjGapQnAJ8bmb9rm7brAPA\nxQARsQt4NHDqQNevoNQO0EOpHaCnUjtAT6V2gJ5K7QA9ldoBeiq1A1Q31A13feaKrgR+NSJuBg4C\nNwP3rv/WPcDObnkHcDawu1sv3dfa62yy3/X+6/sbyzP1dcdz+4/n6vIRtsJQPYonA5dn5oXd+quB\n+zLztXOO+Qzw3Zn5lTXb7VFI0kKm0aP4c+CxEbEzIo4D/jnwntk3RMSJ3T4i4sXAh9YWCUlSewYp\nFJn5DeAlwAeATwG/l5mHIuLSiLi0e9sTgIMRcRh4BnDZENeup9QO0EOpHaCnUjtAT6V2gJ5K7QA9\nldoBeiq1A1Q32B8FzMzrgevXbPuNmeUbgccNdT1J0tbwbz1J0uRNo0chSdqmLBRLK7UD9FBqB+ip\n1A7QU6kdoKdSO0BPpXaAnkrtANVZKCRJc9mjkKTJG7dH0eSjUMFHoUpSK5qcesrM5l/79u2rnmE7\nZDSnOVt/TSHn2JosFJKkdjTZo2gtkyS1LML7KCRJFVkollRKqR1hU1PICOYcmjmHNZWcY7JQSJLm\nskchSRNnj0KSVJWFYklTmLecQkYw59DMOayp5ByThUKSNJc9CkmaOHsUkqSqLBRLmsK85RQygjmH\nZs5hTSXnmCwUkqS57FFI0sTZo5AkVWWhWNIU5i2nkBHMOTRzDmsqOcfU5BPuInzCnSS1oslC4TOz\nJWkR4/7HtVNPkqS5LBRLK7UD9FBqB+ip1A7QU6kdoKdSO0BPpXaAnkrtANVZKCRJcy18H0VEfCUz\nH7zUxSLeBpwL3AN8FLg0M7+x5j1pj0KSFtHefRRH81P8rZn5+Mz8buBBwE8cxbkkSVtg6amnWHFV\nRByMiFsi4p912x8QEW+IiEMR8UcR8V8i4rkAmXn9zCk+Bpx6dPFrKrUD9FBqB+ip1A7QU6kdoKdS\nO0BPpXaAnkrtANUdza/HXgw8CTgLOBn4WER8GDgPeHRmnhkRjwAOAW+ePTAijgVeALzsKK4vSdoC\ny/Qo7s7Mh0TE64EDmfmWbvs1wDuB7wP2Z+bvdNvfBbwtM6+bOcdvAndn5svXOb89CklayLg9iqP5\nRJFsfJfH2u3/bz0i9gLfkZkv3vjUe4Cd3fIO4Gxgd7deuq+uu+666/fX9dXlI2yJzFzoxconAYDn\nAO9npc9xcpf44cCPAO9lpTg8AvhL4OLumJ8AbgC+bc75E3ICr30NZNgOGc1pztZfU8hJLvqzfJHX\nMp8osisw746IpwAHum2vzMwvdlNN5wOfAj4HfAL4q+7YN3YF5cbu7zm9KzN/cYkMkqQtMsrzKCLi\n+Mz8PxHxHcBNwD/KzC/2PDaxRyFJC2i3RzHP+yJiB3Ac8At9i4QkqT2j/AmPzHxaZp6TmU/MzGvG\nuEZ9pXaAHkrtAD2V2gF6KrUD9FRqB+ip1A7QU6kdoDr/1pMkaa4mn5ltj0KSFtHe33qSJN2PNPqE\nOx+FKkmtaPITxZg3jgz12rdvX/UM2yGjOc3Z+msKOcfWZI+itUyS1LIIexSSpIosFEsqpdSOsKkp\nZARzDs2cw5pKzjFZKCRJc9mjkKSJs0chSarKQrGkKcxbTiEjmHNo5hzWVHKOyUIhSZrLHoUkTZw9\nCklSVRaKJU1h3nIKGcGcQzPnsKaSc0wWCknSXPYoJGni7FFIkqqyUCxpCvOWU8gI5hyaOYc1lZxj\nslBIkuayRyFJEzd2j6LJR6FG+ChUSWpFo1NPOYHXvgYybIeM5jRn668p5BxXo4VCktSKJnsUW1Eh\nJWn72Gb3UUTEkyLimVt9XUnScra0UETEA4FzgB/YyuuOo9QO0EOpHaCnUjtAT6V2gJ5K7QA9ldoB\neiq1A1S31G89RcTxwDuAU4BjgCuAvwZeD/wNcANwemY+OyIuB84ATgc+CzwVeFBEnAe8JjPfebTf\nhCRpPEv1KCLiucAzMvNfdOsnAgeBp2XmHRHxe8CDMvOHukLxLOC8zPzbiHghcG5mvmyDc9ujkKSF\ntNmjuAV4ekRc2X0yOB34TGbe0e1/K7AaOoH3ZObfdusxs0+S1Lilpp4y87aIOIeVTwq/CPzJmres\nLQR/M3v45lfYA+zslncAZwO7u/XSfa29vrqtlTzrra/NWjvPRuv7gZ9sKM9G66vLreTZaN3x3P7j\nubp8hK2w7NTTI4EvZebXIuIHgX8FnAl8X2beGRG/Cxw/M/V0d2a+rjv2YuCHMnPPBueeyNRT4Zv/\neK0qtJ8RzDm0gjmHVGg/57hTT8sWiguAq4D7gK8D/xI4GfgVVj49fAQ4o2tm72WlUPxyd+xJwAeA\nY1mnmT2dQiFJrWiwUGx60oh/ArwiM5+9xLEWCklaSJvN7D62+U/7UjtAD6V2gJ5K7QA9ldoBeiq1\nA/RUagfoqdQOUN0ofz02Mz8EfGiMc0uStpZ/60mSJm+6U0+SpG3AQrG0UjtAD6V2gJ5K7QA9ldoB\neiq1A/RUagfoqdQOUF2TT7jzxm1JakeThaK1vokktWzsx0c79SRJmstCsaRSSu0Im5pCRjDn0Mw5\nrKnkHJOFQpI0V5P3UbSWSZJaFuF9FJKkiiwUS5rCvOUUMoI5h2bOYU0l55gsFJKkuexRSNLE2aOQ\nJFVloVjSFOYtp5ARzDk0cw5rKjnHZKGQJM1lj0KSJs4ehSSpKgvFkqYwbzmFjGDOoZlzWFPJOSYL\nhSRpLnsUkjRx9igkSVU1+YS7sZ/WJEnqr9FPFDmB174GMmyHjOY0Z+uvKeQcV5M9iq34xiVp+7BH\nIUmqyEKxtFI7QA+ldoCeSu0APZXaAXoqtQP0VGoH6KnUDlDd3EIREfdFxC/NrL8iIvaOH0uS1Iq5\nPYqI+BrweWBXZv5lRPw08ODM/PnRAtmjkKQF1e1R3AO8CfiptTsiYmdE/GlEHIiIP46I07rtb4mI\nX42IGyLijoh47swxr4yIj3bHXD7kNyJJGkefHsUbgOdHxAlrtv9H4OrMfBLwNuDXZvb9ncx8KvCD\nwJUAEXEB8J2ZuQs4Bzg3Ir73aL+BekrtAD2U2gF6KrUD9FRqB+ip1A7QU6kdoKdSO0B1m95wl5l3\nR8Q1wMuAr87sejLww93yW4H/sHoI8AfdsYci4hHd9guACyLi5m79eOA7gY/8/1fdA+zslncAZwO7\nu/XSfa29zib7Xe+/vr+xPFNfdzy3/3iuLh9hK2zWo7g7Mx8SEScBnwCu7o75+Yj4X8AjM/MbEXEs\n8IXMPDkirgbel5nvWnOOXwI+nZlvmhvIHoUkLaiB+ygy80vAO4Af55s/xf8r8KPd8vOBD29ymg8A\nl0TE8QARcUpEnLxwYknSltqsUMz+p/3rgIfNrL8UeFFEHGClUFy2wXEJkJkfBK4FboyIW1gpPA9e\nMncDSu0APZTaAXoqtQP0VGoH6KnUDtBTqR2gp1I7QHVzexSZecLM8hdZ6Susrn8WOH+dY1405xy/\nxrc2vSVJjfNvPUnS5DXQo5Ak3X9ZKJZWagfoodQO0FOpHaCnUjtAT6V2gJ5K7QA9ldoBqrNQSJLm\navIJd+AT7iSpFU0WitYa7JLUsrEfH+3U05JKKbUjbGoKGcGcQzPnsKaSc0wWCknSXE3eR9FaJklq\nWYT3UUiSKrJQLGkK85ZTyAjmHJo5hzWVnGOyUEiS5rJHIUkTZ49CklSVhWJJU5i3nEJGMOfQzDms\nqeQck4VCkjSXPQpJmjh7FJKkqiwUS5rCvOUUMoI5h2bOYU0l55gsFJKkuexRSNLE2aOQJFVloVjS\nFOYtp5ARzDk0cw5rKjnH1OQT7sZ+WpMkqb8mCwXYo5Ck/nwUqiSpIgvF0krtAD2U2gF6KrUD9FRq\nB+ip1A7QU6kdoKdSO0B1FgpJ0lyj3UcRERcBn87MQwsel/YoJGkR072P4jnAE0Y8vyRpCyxUKCLi\n3RHx5xHxyYh4cbftKzP7fyQiro6IpwDPBq6KiJsj4jERcXZE/FlEHIiI6yJix7DfylYrtQP0UGoH\n6KnUDtBTqR2gp1I7QE+ldoCeSu0A1S36ieKSzPz7wD8AXhYRD+Vb54kSIDNvBN4DvCIzz8nMO4Fr\ngFdm5pOAg8Deo04vSRrdovdRXBYRP9wtnwo8dpP3B0BEnAicmJkf6bb/DvDOjQ/bA+zslncAZwO7\nu/XSfXV98/XdjeWZt84m+1tY391YnnnrbLK/hfXdjeWZt84m+2vkKcARtkLvZnZE7AauAJ6emV+L\niH3A5cB7M/OE7j0vAM7PzBdFxNXdvuu6QnFLZj66e98ZwDsy89x1rmMzW5IW0k4z+wTgS12ROBN4\ncrf9f0bE4yPiAaw0sFd/yt/dHUNm/hXwpYg4r9v3Y0x+4q/UDtBDqR2gp1I7QE+ldoCeSu0APZXa\nAXoqtQNUt0iheD/wwIj4FPAa4EZWisLPAO8DbgC+MPP+twOvjIiPR8RjgBey0tw+AJwF/MIA+SVJ\nI2vyeRROPUnSItqZepIk3Q9ZKJZWagfoodQO0FOpHaCnUjtAT6V2gJ5K7QA9ldoBqrNQSJLmskch\nSZNnj0KSVFGjT7jzUaiS1IomP1FkZvOvffv2Vc+wHTKa05ytv6aQc2xN9ihayyRJLYuwRyFJqshC\nsaRSSu0Im5pCRjDn0Mw5rKnkHJOFYkn79++vHWFTU8gI5hyaOYc1lZxjslAs6ctf/nLtCJuaQkYw\n59DMOayp5ByThUKSNJeFYklHjhypHWFTU8gI5hyaOYc1lZxjavLXY2tnkKSpGfPXY5srFJKktjj1\nJEmay0IhSZpr8EIRERdGxOGIuC0iXrXO/pMi4t0RcSAiboqIJ87suywiDkbEJyPispnt/zQi/iIi\n7o2I71lzvld31zocERe0mDMidkbEVyPi5u71hooZr4qIQ90x10XEiTP7WhrLdXMuO5Yj5ryie//+\niPiTiDhtZl9L47luztbGc2b/T0fEfRHx0JltzYznRjlbG8+IuDwi7prJ88yZff3Hc+A/THUMcDuw\nEzgW2A+cueY9VwH/plt+HPDH3fJ3AQeBb+vO80HgjG7f44G/B+wDvmfmXE/ornFsd83bgQc0mHMn\ncLCRsXz66hgBVwJXNjqWG+VceCxHzvmQmeNfCvxWo+O5Uc6mxrPbfxrwfuAzwENbHM85OZsaT2Av\n8PJ1rrfQeA79iWIXcHtmHsnMe4C3Axetec+ZrPwgJTNvBXZGxMO77Tdl5tcy817gQ8DF3fsOZ+an\n17neRcDvZuY9mXmk+2Z3NZhzGWNl/GBm3tcdfxNwarfc2lhulHNZY+W8e+b4BwP/u1tubTw3yrms\nUXJ2fhn412vO1dR4zsm5rDFzrvfbUAuN59CF4hTgczPrd3XbZh2g+yYiYhfw6O49B4HvjYiHRsS3\nA89i8x8Of7e7xrzrtZAT4PTuo1+JiPMayXgJ8IfdcstjOZsTFh/LUXNGxL+LiM8Ce4B/321ubjxn\ncr6QlU9pq5oZz4i4CLgrM29Zc66mxnNOTmhoPDsv7aar3hwRO7ptC43n0IWiz+/aXgnsiIibgZcA\nNwP3ZuZh4LXAHwHXd9vv2/AsR5dhq3N+ATgtM88BXg5cGxEPqZkxIn4O+HpmXnuUGbY65zJjOWrO\nzPy5zHwUcDXwK0eZYStyvgV4fbe5lfG8NyIeBPwsK9Mlq+bdG1BjPDfL2cp4rv67vxE4HTgb+O/A\n65bJMPQT7j7PyrzdqtP41qq1+hH4ktX1iPgMcGe377eB3+62vwb47ILXO7Xb1lTOzPw68PVu+RMR\ncQfwWOATNTJGxB7gB4Dz51yv+liul3PJsRw154xr+eYnn+bGc72cjY3nGazMlx+ICFgZs49HxD9c\n53o1x3OjnLsy84u0M550eVbf/1vAeze43vzx3Kh5scyLlcJzRzeIx7F+Q+ZE4Lhu+cXAW2b2Pbz7\n+ijgEHDCmmP3AefOrK82ZI5jpWreQXcTYWM5HwYc0y0/hpX/AeyokRG4EPgL4GFrztXUWM7JufBY\njpzzsTPveSnwnxsdz41yNjWea45fr5ndxHjOydnUeAKPnHnPTwHXLjOeSxWETb7hZwK3stIceXW3\n7VLg0m75Kd3+w8DvAyfOHPthVn447AeeNrP9OazM330V+B/A9TP7fra71mHgGS3mBJ4LfJKVj4Qf\nB55VMeNtwH/rstwMvKHRsVw357JjOWLO32dljng/8C66/8M2OJ7r5mRlzruZ8Vxz/jvpfgC3Np4b\n5WxtPIFrgFtY6W/8AfCIZcbTP+EhSZrLO7MlSXNZKCRJc1koJElzWSgkSXNZKCRJc1koJElzWSgk\nSXNZKCRJc/1fQ1dJ0Zq/dCcAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x1095c3ad0>"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "min_samples_leaf"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results = []\n",
      "min_samples_leaf_options = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "\n",
      "for min_samples in min_samples_leaf_options:\n",
      "    model = RandomForestClassifier(n_estimators=30,  \n",
      "                                  n_jobs=-1, \n",
      "                                  random_state=42, \n",
      "                                  max_features=0.2, \n",
      "                                  min_samples_leaf=min_samples)\n",
      "    model.fit(X, y)\n",
      "    print min_samples, \"min samples\"\n",
      "    roc = roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
      "    print \"C-stat: \", roc\n",
      "    results.append(roc)\n",
      "    print \"\"\n",
      "    \n",
      "pd.Series(results, min_samples_leaf_options).plot();"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 min samples\n",
        "C-stat: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.0\n",
        "\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " min samples\n",
        "C-stat: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1.0\n",
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " min samples\n",
        "C-stat: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.999532163743\n",
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " min samples\n",
        "C-stat: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.999064327485\n",
        "\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " min samples\n",
        "C-stat: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.998362573099\n",
        "\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " min samples\n",
        "C-stat: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.997660818713\n",
        "\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " min samples\n",
        "C-stat: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.996257309942\n",
        "\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " min samples\n",
        "C-stat: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.99649122807\n",
        "\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " min samples\n",
        "C-stat: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.996023391813\n",
        "\n",
        "10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " min samples\n",
        "C-stat: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.996023391813\n",
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEACAYAAACpoOGTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf17PnwsCa4uLAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x1094fe790>"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Final model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = RandomForestClassifier(n_estimators=30,\n",
      "                              n_jobs=-1, \n",
      "                              random_state=42, \n",
      "                              max_features=0.2, \n",
      "                              min_samples_leaf=2)\n",
      "model.fit(X, y)\n",
      "roc = roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
      "print \"C-stat: \", roc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C-stat:  1.0\n"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logit_roc_auc = roc_auc_score(y_test, model.predict(X_test))\n",
      "print \"Logistic AUC = %2.2f\" % logit_roc_auc\n",
      "print classification_report(y_test, model.predict(X_test) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Logistic AUC = 0.99\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       1.00      0.99      0.99        95\n",
        "          1       0.98      1.00      0.99        45\n",
        "\n",
        "avg / total       0.99      0.99      0.99       140\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Grid Search\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "n_estimators = [300,400,500]\n",
      "max_features = ['auto', 'sqrt','log2']\n",
      "min_samples_split = [3,5,7]\n",
      "\n",
      "\n",
      "rfc = RandomForestClassifier(n_jobs=1)\n",
      "#Parameters of pipelines can be set using \u2018__\u2019 separated parameter names:\n",
      "estimator = GridSearchCV(rfc,\n",
      "                         dict(n_estimators=n_estimators,\n",
      "                              max_features=max_features,\n",
      "                              min_samples_split=min_samples_split\n",
      "                              ), cv=None, n_jobs=-1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "estimator.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 62,
       "text": [
        "GridSearchCV(cv=None,\n",
        "       estimator=RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=None, max_features='auto',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, n_estimators=10, n_jobs=1,\n",
        "            oob_score=False, random_state=None, verbose=0),\n",
        "       fit_params={}, iid=True, loss_func=None, n_jobs=-1,\n",
        "       param_grid={'min_samples_split': [3, 5, 7], 'max_features': ['auto', 'sqrt', 'log2'], 'n_estimators': [300, 400, 500]},\n",
        "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
        "       verbose=0)"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "estimator.best_estimator_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 63,
       "text": [
        "RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=None, max_features='auto',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=3, n_estimators=300, n_jobs=1,\n",
        "            oob_score=False, random_state=None, verbose=0)"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "best_rfc = estimator.best_estimator_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Accuracy"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "accuracy = accuracy_score(y_test, best_rfc.predict(X_test))\n",
      "print \"Accuracy: \", accuracy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy:  0.971428571429\n"
       ]
      }
     ],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_hat = best_rfc.predict(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_hat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 73,
       "text": [
        "array([0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1,\n",
        "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
        "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
        "       0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
        "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
        "       1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
        "       0, 0])"
       ]
      }
     ],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_test"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 74,
       "text": [
        "array([0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1,\n",
        "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
        "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
        "       0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
        "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
        "       1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
        "       0, 0])"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "correct = 0\n",
      "total = y_test.shape[0]\n",
      "for pred_val, truth_val in zip(y_hat, y_test):\n",
      "    if pred_val == truth_val:\n",
      "        correct +=1\n",
      "\n",
      "print correct / float(total)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.971428571429\n"
       ]
      }
     ],
     "prompt_number": 75
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Precision and Recall"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print classification_report(y_test, best_rfc.predict(X_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.98      0.98      0.98        95\n",
        "          1       0.96      0.96      0.96        45\n",
        "\n",
        "avg / total       0.97      0.97      0.97       140\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import confusion_matrix\n",
      "print confusion_matrix(y_test, best_rfc.predict(X_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[93  2]\n",
        " [ 2 43]]\n"
       ]
      }
     ],
     "prompt_number": 78
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Precision = .96\n",
      "####Recall = .96"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "roc = roc_auc_score(y_test, best_rfc.predict_proba(X_test)[:,1])\n",
      "print \"AUC Score: \", roc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "AUC Score:  0.996023391813\n"
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####K-FOLD CROSS VALIDATION"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import cross_validation\n",
      "scores = cross_validation.cross_val_score(best_rfc, X, y, cv=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 88,
       "text": [
        "array([ 0.92957746,  0.98571429,  0.97142857,  0.91428571,  0.97142857,\n",
        "        0.95714286,  0.97142857,  0.98571429,  0.98550725,  1.        ])"
       ]
      }
     ],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math\n",
      "mean_score = scores.mean()\n",
      "std_dev = scores.std()\n",
      "std_error = scores.std() / math.sqrt(scores.shape[0])\n",
      "ci =  2.262 * std_error\n",
      "lower_bound = mean_score - ci\n",
      "upper_bound = mean_score + ci\n",
      "\n",
      "print \"Score is %f +/-  %f\" % (mean_score, ci)\n",
      "print '95 percent probability that if this experiment were repeated over and over the average score would be between %f and %f' % (lower_bound, upper_bound)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Score is 0.967223 +/-  0.018190\n",
        "95 percent probability that if this experiment were repeated over and over the average score would be between 0.949033 and 0.985413\n"
       ]
      }
     ],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}